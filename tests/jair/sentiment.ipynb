{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\jairp\\anaconda3\\lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "[nltk_data] Downloading package sentiwordnet to\n",
      "[nltk_data]     C:\\Users\\jairp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package sentiwordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\jairp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# General Imports\n",
    "import pprint \n",
    "import re\n",
    "import zipfile \n",
    "import gzip\n",
    "import shutil\n",
    "from tqdm.notebook import tqdm\n",
    "from emoji import demojize\n",
    "from typing import Union, List\n",
    "\n",
    "#BERT\n",
    "from transformers import pipeline\n",
    "\n",
    "# Load the sentiment analysis pipeline\n",
    "sentiment_pipeline = pipeline(\"sentiment-analysis\", model=\"distilbert-base-uncased\")\n",
    "\n",
    "# Data Analysis and visualizations\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "# Import GenSim\n",
    "import gensim\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.models.phrases import Phrases, Phraser\n",
    "\n",
    "# Import Spacy\n",
    "import spacy\n",
    "from spacy.lang.en import English\n",
    "nlp = spacy.load(\"en_core_web_md\", disable=[\"parser\", \"ner\"])\n",
    "\n",
    "# Import NLTK\n",
    "import nltk\n",
    "from nltk.corpus import sentiwordnet as swn\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Download necessary NLTK data\n",
    "nltk.download('stopwords', quiet=True)\n",
    "stop_words = set(stopwords.words('english'))\n",
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('sentiwordnet')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # verify working directory of the notebook \n",
    "# import os \n",
    "# print(os.getcwd())\n",
    "# import sys\n",
    "# path = os.path.abspath(os.path.join('../../')) # or the path to your source code\n",
    "# sys.path.insert(0, path)\n",
    "# print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the zip files\n",
    "\n",
    "# Specify the path to the zip file\n",
    "zip_file_path = 'data_raw/reddit_wsb.csv.zip'\n",
    "\n",
    "# Extract the zip file\n",
    "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall('data_raw')\n",
    "\n",
    "# Read the CSV using Pandas\n",
    "csv_file_path = 'data_raw/reddit_wsb.csv'\n",
    "df = pd.read_csv(csv_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_sentiment(word):\n",
    "    \"\"\"\n",
    "    Estimate the sentiment of a single word using SentiWordNet.\n",
    "\n",
    "    Args:\n",
    "        word (str): The word to estimate the sentiment for.\n",
    "\n",
    "    Returns:\n",
    "        float: The sentiment score of the word.\n",
    "    \"\"\"\n",
    "    # Get the list of SentiWordNet synsets for the word\n",
    "    synsets = list(swn.senti_synsets(word))\n",
    "    \n",
    "    if not synsets:\n",
    "        return 0\n",
    "    \n",
    "    # Take the first sense, the most common\n",
    "    return synsets[0].pos_score() - synsets[0].neg_score()\n",
    "\n",
    "# Compute the sentiment score \n",
    "def bert_sentiment_analysis(text):\n",
    "    \"\"\"\n",
    "    Perform sentiment analysis using BERT model.\n",
    "\n",
    "    Args:\n",
    "        text (str): The input text for sentiment analysis.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing the sentiment label ('POSITIVE' or 'NEGATIVE') and a confidence score.\n",
    "\n",
    "    \"\"\"\n",
    "    # Perform sentiment analysis\n",
    "    result = sentiment_pipeline(text)\n",
    "    \n",
    "    # The result includes the label ('POSITIVE' or 'NEGATIVE') and a confidence score\n",
    "    return result\n",
    "\n",
    "# # Compute the sentiment score (paralelized)\n",
    "# def batch_sentiment_analysis(texts, batch_size=8):\n",
    "#     results = []\n",
    "#     for i in range(0, len(texts), batch_size):\n",
    "#         batch = texts[i:i+batch_size]\n",
    "#         results.extend(sentiment_pipeline(batch))\n",
    "#     return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing functions\n",
    "\n",
    "def preprocess_text(texts: Union[str, List[str], pd.Series], clean_emojis: bool = False) -> Union[str, List[str]]:\n",
    "    \"\"\"\n",
    "    Preprocesses a list of texts by cleaning them and removing stopwords.\n",
    "\n",
    "    Args:\n",
    "        texts (Union[str, List[str], pd.Series]): The input texts to preprocess.\n",
    "        clean_emojis (bool, optional): Whether to clean emojis or convert them to text. Defaults to False.\n",
    "\n",
    "    Returns:\n",
    "        Union[str, List[str]]: The preprocessed texts.\n",
    "    \"\"\"\n",
    "    cleaned_texts = []\n",
    "\n",
    "    # Processing texts using Spacy pipeline\n",
    "    for doc in tqdm(nlp.pipe(texts, batch_size=20), total=len(texts), desc=\"Cleaning Texts\"):\n",
    "\n",
    "        # Handle emojis: translate to text if not removing, else remove\n",
    "        if clean_emojis:\n",
    "            doc = re.sub(r':[^:]+:', '', demojize(doc.text))  # Remove emojis\n",
    "        else:\n",
    "            doc = demojize(doc.text)  # Convert emojis to text\n",
    "\n",
    "        # Tokenization and preprocessing\n",
    "        tokens = [token.text.lower() for token in nlp(doc) if token.text.isalpha()]\n",
    "\n",
    "        # Removing stopwords and short tokens\n",
    "        tokens = [token for token in tokens if token not in stop_words and len(token) > 1]\n",
    "\n",
    "        cleaned_texts.append(' '.join(tokens))  # Rejoin tokens into a string\n",
    "\n",
    "    return cleaned_texts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>score</th>\n",
       "      <th>id</th>\n",
       "      <th>url</th>\n",
       "      <th>comms_num</th>\n",
       "      <th>created</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>It's not about the money, it's about sending a...</td>\n",
       "      <td>55</td>\n",
       "      <td>l6ulcx</td>\n",
       "      <td>https://v.redd.it/6j75regs72e61</td>\n",
       "      <td>6</td>\n",
       "      <td>1.611863e+09</td>\n",
       "      <td>2021-01-28 21:37:41</td>\n",
       "      <td>It's not about the money, it's about sending a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Math Professor Scott Steiner says the numbers ...</td>\n",
       "      <td>110</td>\n",
       "      <td>l6uibd</td>\n",
       "      <td>https://v.redd.it/ah50lyny62e61</td>\n",
       "      <td>23</td>\n",
       "      <td>1.611862e+09</td>\n",
       "      <td>2021-01-28 21:32:10</td>\n",
       "      <td>Math Professor Scott Steiner says the numbers ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Exit the system</td>\n",
       "      <td>0</td>\n",
       "      <td>l6uhhn</td>\n",
       "      <td>https://www.reddit.com/r/wallstreetbets/commen...</td>\n",
       "      <td>47</td>\n",
       "      <td>1.611862e+09</td>\n",
       "      <td>2021-01-28 21:30:35</td>\n",
       "      <td>Exit the system\\n\\nThe CEO of NASDAQ pushed to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NEW SEC FILING FOR GME! CAN SOMEONE LESS RETAR...</td>\n",
       "      <td>29</td>\n",
       "      <td>l6ugk6</td>\n",
       "      <td>https://sec.report/Document/0001193125-21-019848/</td>\n",
       "      <td>74</td>\n",
       "      <td>1.611862e+09</td>\n",
       "      <td>2021-01-28 21:28:57</td>\n",
       "      <td>NEW SEC FILING FOR GME! CAN SOMEONE LESS RETAR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Not to distract from GME, just thought our AMC...</td>\n",
       "      <td>71</td>\n",
       "      <td>l6ufgy</td>\n",
       "      <td>https://i.redd.it/4h2sukb662e61.jpg</td>\n",
       "      <td>156</td>\n",
       "      <td>1.611862e+09</td>\n",
       "      <td>2021-01-28 21:26:56</td>\n",
       "      <td>Not to distract from GME, just thought our AMC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>WE BREAKING THROUGH</td>\n",
       "      <td>405</td>\n",
       "      <td>l6uf7d</td>\n",
       "      <td>https://i.redd.it/2wef8tc062e61.png</td>\n",
       "      <td>84</td>\n",
       "      <td>1.611862e+09</td>\n",
       "      <td>2021-01-28 21:26:30</td>\n",
       "      <td>WE BREAKING THROUGH\\n\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SHORT STOCK DOESN'T HAVE AN EXPIRATION DATE</td>\n",
       "      <td>317</td>\n",
       "      <td>l6uf6d</td>\n",
       "      <td>https://www.reddit.com/r/wallstreetbets/commen...</td>\n",
       "      <td>53</td>\n",
       "      <td>1.611862e+09</td>\n",
       "      <td>2021-01-28 21:26:27</td>\n",
       "      <td>SHORT STOCK DOESN'T HAVE AN EXPIRATION DATE\\n\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>THIS IS THE MOMENT</td>\n",
       "      <td>405</td>\n",
       "      <td>l6ub9l</td>\n",
       "      <td>https://www.reddit.com/r/wallstreetbets/commen...</td>\n",
       "      <td>178</td>\n",
       "      <td>1.611862e+09</td>\n",
       "      <td>2021-01-28 21:19:31</td>\n",
       "      <td>THIS IS THE MOMENT\\n\\nLife isn't fair. My moth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Currently Holding AMC and NOK - Is it retarded...</td>\n",
       "      <td>200</td>\n",
       "      <td>l6ub4i</td>\n",
       "      <td>https://i.redd.it/6k2z7ouo42e61.png</td>\n",
       "      <td>161</td>\n",
       "      <td>1.611862e+09</td>\n",
       "      <td>2021-01-28 21:19:16</td>\n",
       "      <td>Currently Holding AMC and NOK - Is it retarded...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>I have nothing to say but BRUH I am speechless...</td>\n",
       "      <td>291</td>\n",
       "      <td>l6uas9</td>\n",
       "      <td>https://i.redd.it/bfzzw2yo42e61.jpg</td>\n",
       "      <td>27</td>\n",
       "      <td>1.611862e+09</td>\n",
       "      <td>2021-01-28 21:18:37</td>\n",
       "      <td>I have nothing to say but BRUH I am speechless...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  score      id  \\\n",
       "0  It's not about the money, it's about sending a...     55  l6ulcx   \n",
       "1  Math Professor Scott Steiner says the numbers ...    110  l6uibd   \n",
       "2                                    Exit the system      0  l6uhhn   \n",
       "3  NEW SEC FILING FOR GME! CAN SOMEONE LESS RETAR...     29  l6ugk6   \n",
       "4  Not to distract from GME, just thought our AMC...     71  l6ufgy   \n",
       "5                                WE BREAKING THROUGH    405  l6uf7d   \n",
       "6        SHORT STOCK DOESN'T HAVE AN EXPIRATION DATE    317  l6uf6d   \n",
       "7                                 THIS IS THE MOMENT    405  l6ub9l   \n",
       "8  Currently Holding AMC and NOK - Is it retarded...    200  l6ub4i   \n",
       "9  I have nothing to say but BRUH I am speechless...    291  l6uas9   \n",
       "\n",
       "                                                 url  comms_num       created  \\\n",
       "0                    https://v.redd.it/6j75regs72e61          6  1.611863e+09   \n",
       "1                    https://v.redd.it/ah50lyny62e61         23  1.611862e+09   \n",
       "2  https://www.reddit.com/r/wallstreetbets/commen...         47  1.611862e+09   \n",
       "3  https://sec.report/Document/0001193125-21-019848/         74  1.611862e+09   \n",
       "4                https://i.redd.it/4h2sukb662e61.jpg        156  1.611862e+09   \n",
       "5                https://i.redd.it/2wef8tc062e61.png         84  1.611862e+09   \n",
       "6  https://www.reddit.com/r/wallstreetbets/commen...         53  1.611862e+09   \n",
       "7  https://www.reddit.com/r/wallstreetbets/commen...        178  1.611862e+09   \n",
       "8                https://i.redd.it/6k2z7ouo42e61.png        161  1.611862e+09   \n",
       "9                https://i.redd.it/bfzzw2yo42e61.jpg         27  1.611862e+09   \n",
       "\n",
       "             timestamp                                               text  \n",
       "0  2021-01-28 21:37:41  It's not about the money, it's about sending a...  \n",
       "1  2021-01-28 21:32:10  Math Professor Scott Steiner says the numbers ...  \n",
       "2  2021-01-28 21:30:35  Exit the system\\n\\nThe CEO of NASDAQ pushed to...  \n",
       "3  2021-01-28 21:28:57  NEW SEC FILING FOR GME! CAN SOMEONE LESS RETAR...  \n",
       "4  2021-01-28 21:26:56  Not to distract from GME, just thought our AMC...  \n",
       "5  2021-01-28 21:26:30                            WE BREAKING THROUGH\\n\\n  \n",
       "6  2021-01-28 21:26:27  SHORT STOCK DOESN'T HAVE AN EXPIRATION DATE\\n\\...  \n",
       "7  2021-01-28 21:19:31  THIS IS THE MOMENT\\n\\nLife isn't fair. My moth...  \n",
       "8  2021-01-28 21:19:16  Currently Holding AMC and NOK - Is it retarded...  \n",
       "9  2021-01-28 21:18:37  I have nothing to say but BRUH I am speechless...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Fill all the NaN values in the body column with an empty string\n",
    "df['body'] = df['body'].fillna('')\n",
    "\n",
    "# Combine the title and bodyy into a single column text, separated by two newlines\n",
    "df['text'] = df['title'] + '\\n\\n' + df['body']\n",
    "\n",
    "# drop the body column \n",
    "df = df.drop(columns=['body'])\n",
    "\n",
    "# Preview the loaded data \n",
    "display(df.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = pd.DataFrame(df['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd2725837df24b56a1d9913a90eb1985",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Cleaning Texts:   0%|          | 0/53187 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Preprocess each title and track progress with tqdm\n",
    "texts['processed_text'] = preprocess_text(texts['title'], clean_emojis=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>processed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>It's not about the money, it's about sending a...</td>\n",
       "      <td>money sending message</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Math Professor Scott Steiner says the numbers ...</td>\n",
       "      <td>math professor scott steiner says numbers spel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Exit the system</td>\n",
       "      <td>exit system</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NEW SEC FILING FOR GME! CAN SOMEONE LESS RETAR...</td>\n",
       "      <td>new sec filing gme someone less retarded pleas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Not to distract from GME, just thought our AMC...</td>\n",
       "      <td>distract gme thought amc brothers aware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>WE BREAKING THROUGH</td>\n",
       "      <td>breaking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SHORT STOCK DOESN'T HAVE AN EXPIRATION DATE</td>\n",
       "      <td>short stock expiration date</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>THIS IS THE MOMENT</td>\n",
       "      <td>moment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Currently Holding AMC and NOK - Is it retarded...</td>\n",
       "      <td>currently holding amc nok retarded think move ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>I have nothing to say but BRUH I am speechless...</td>\n",
       "      <td>nothing say bruh speechless moon</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  It's not about the money, it's about sending a...   \n",
       "1  Math Professor Scott Steiner says the numbers ...   \n",
       "2                                    Exit the system   \n",
       "3  NEW SEC FILING FOR GME! CAN SOMEONE LESS RETAR...   \n",
       "4  Not to distract from GME, just thought our AMC...   \n",
       "5                                WE BREAKING THROUGH   \n",
       "6        SHORT STOCK DOESN'T HAVE AN EXPIRATION DATE   \n",
       "7                                 THIS IS THE MOMENT   \n",
       "8  Currently Holding AMC and NOK - Is it retarded...   \n",
       "9  I have nothing to say but BRUH I am speechless...   \n",
       "\n",
       "                                      processed_text  \n",
       "0                              money sending message  \n",
       "1  math professor scott steiner says numbers spel...  \n",
       "2                                        exit system  \n",
       "3  new sec filing gme someone less retarded pleas...  \n",
       "4            distract gme thought amc brothers aware  \n",
       "5                                           breaking  \n",
       "6                        short stock expiration date  \n",
       "7                                             moment  \n",
       "8  currently holding amc nok retarded think move ...  \n",
       "9                   nothing say bruh speechless moon  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(texts.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset a number of texts \n",
    "df_test = texts.iloc[0:1000, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jairp\\AppData\\Local\\Temp\\ipykernel_39852\\2738347497.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  batch['sentiment'] = sentiment_pipeline(batch['processed_text'].tolist())\n",
      "C:\\Users\\jairp\\AppData\\Local\\Temp\\ipykernel_39852\\2738347497.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  batch['sentiment'] = sentiment_pipeline(batch['processed_text'].tolist())\n",
      "C:\\Users\\jairp\\AppData\\Local\\Temp\\ipykernel_39852\\2738347497.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  batch['sentiment'] = sentiment_pipeline(batch['processed_text'].tolist())\n",
      "C:\\Users\\jairp\\AppData\\Local\\Temp\\ipykernel_39852\\2738347497.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  batch['sentiment'] = sentiment_pipeline(batch['processed_text'].tolist())\n",
      "C:\\Users\\jairp\\AppData\\Local\\Temp\\ipykernel_39852\\2738347497.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  batch['sentiment'] = sentiment_pipeline(batch['processed_text'].tolist())\n",
      "C:\\Users\\jairp\\AppData\\Local\\Temp\\ipykernel_39852\\2738347497.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  batch['sentiment'] = sentiment_pipeline(batch['processed_text'].tolist())\n",
      "C:\\Users\\jairp\\AppData\\Local\\Temp\\ipykernel_39852\\2738347497.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  batch['sentiment'] = sentiment_pipeline(batch['processed_text'].tolist())\n",
      "C:\\Users\\jairp\\AppData\\Local\\Temp\\ipykernel_39852\\2738347497.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  batch['sentiment'] = sentiment_pipeline(batch['processed_text'].tolist())\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>processed_text</th>\n",
       "      <th>sentiment_label</th>\n",
       "      <th>sentiment_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>It's not about the money, it's about sending a...</td>\n",
       "      <td>money sending message</td>\n",
       "      <td>1</td>\n",
       "      <td>0.542390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Math Professor Scott Steiner says the numbers ...</td>\n",
       "      <td>math professor scott steiner says numbers spel...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.530862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Exit the system</td>\n",
       "      <td>exit system</td>\n",
       "      <td>1</td>\n",
       "      <td>0.527198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NEW SEC FILING FOR GME! CAN SOMEONE LESS RETAR...</td>\n",
       "      <td>new sec filing gme someone less retarded pleas...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.528212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Not to distract from GME, just thought our AMC...</td>\n",
       "      <td>distract gme thought amc brothers aware</td>\n",
       "      <td>1</td>\n",
       "      <td>0.526397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>Looks like we can buy on SoFi*</td>\n",
       "      <td>looks like buy sofi</td>\n",
       "      <td>1</td>\n",
       "      <td>0.530242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>Can't cancel my Revolut order</td>\n",
       "      <td>ca cancel revolut order</td>\n",
       "      <td>1</td>\n",
       "      <td>0.528675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>LOL they are trying so hard to break us!! But ...</td>\n",
       "      <td>lol trying hard break us cheap buying</td>\n",
       "      <td>1</td>\n",
       "      <td>0.525004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>Opening TD Ameritrade. Anyone got a referral c...</td>\n",
       "      <td>opening td ameritrade anyone got referral code</td>\n",
       "      <td>1</td>\n",
       "      <td>0.521101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>This was all coordinated, short laddering comb...</td>\n",
       "      <td>coordinated short laddering combined rh blocki...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.528703</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  title  \\\n",
       "0     It's not about the money, it's about sending a...   \n",
       "1     Math Professor Scott Steiner says the numbers ...   \n",
       "2                                       Exit the system   \n",
       "3     NEW SEC FILING FOR GME! CAN SOMEONE LESS RETAR...   \n",
       "4     Not to distract from GME, just thought our AMC...   \n",
       "...                                                 ...   \n",
       "9995                     Looks like we can buy on SoFi*   \n",
       "9996                      Can't cancel my Revolut order   \n",
       "9997  LOL they are trying so hard to break us!! But ...   \n",
       "9998  Opening TD Ameritrade. Anyone got a referral c...   \n",
       "9999  This was all coordinated, short laddering comb...   \n",
       "\n",
       "                                         processed_text  sentiment_label  \\\n",
       "0                                 money sending message                1   \n",
       "1     math professor scott steiner says numbers spel...                1   \n",
       "2                                           exit system                1   \n",
       "3     new sec filing gme someone less retarded pleas...                1   \n",
       "4               distract gme thought amc brothers aware                1   \n",
       "...                                                 ...              ...   \n",
       "9995                                looks like buy sofi                1   \n",
       "9996                            ca cancel revolut order                1   \n",
       "9997              lol trying hard break us cheap buying                1   \n",
       "9998     opening td ameritrade anyone got referral code                1   \n",
       "9999  coordinated short laddering combined rh blocki...                1   \n",
       "\n",
       "      sentiment_score  \n",
       "0            0.542390  \n",
       "1            0.530862  \n",
       "2            0.527198  \n",
       "3            0.528212  \n",
       "4            0.526397  \n",
       "...               ...  \n",
       "9995         0.530242  \n",
       "9996         0.528675  \n",
       "9997         0.525004  \n",
       "9998         0.521101  \n",
       "9999         0.528703  \n",
       "\n",
       "[10000 rows x 4 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Subset a number of texts \n",
    "df_test = texts.iloc[0:10000, :]\n",
    "\n",
    "# # Apply sentiment analysis using BERT model\n",
    "# df_test.loc[:, 'sentiment'] = sentiment_pipeline(df_test['processed_text'].tolist())\n",
    "\n",
    "import os\n",
    "import concurrent.futures\n",
    "\n",
    "# Get the number of available cores\n",
    "num_cores = os.cpu_count()\n",
    "max_workers = num_cores - 1\n",
    "\n",
    "# Split df_test into 4 batches\n",
    "num_batches = 8\n",
    "batch_size = len(df_test) // num_batches\n",
    "batches = [df_test[i*batch_size:(i+1)*batch_size] for i in range(num_batches)]\n",
    "\n",
    "# Function to process each batch independently\n",
    "def process_batch(batch):\n",
    "    batch['sentiment'] = sentiment_pipeline(batch['processed_text'].tolist())\n",
    "    return batch\n",
    "\n",
    "# Process each batch in parallel using threads\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "    results = executor.map(process_batch, batches)\n",
    "\n",
    "# Combine the results from all batches\n",
    "df_test = pd.concat(results)\n",
    "\n",
    "# Extract the sentiment label and confidence score\n",
    "df_test['sentiment_label'] = df_test['sentiment'].apply(lambda x: x['label'])\n",
    "df_test['sentiment_score'] = df_test['sentiment'].apply(lambda x: x['score'])\n",
    "\n",
    "# Transform the sentiment label to a numerical value\n",
    "df_test['sentiment_label'] = df_test['sentiment_label'].map({'LABEL_1': 1, 'LABEL_0': 0})\n",
    "\n",
    "# Drop original sentiment column if it exists \n",
    "if 'sentiment' in df_test.columns:\n",
    "    df_test = df_test.drop(columns=['sentiment'])\n",
    "\n",
    "# Display\n",
    "df_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 2.15.0\n",
      "No GPUs found.\n",
      "Built with CUDA: True\n",
      "WARNING:tensorflow:From /tmp/ipykernel_43968/2058930311.py:23: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n",
      "GPU available (TensorFlow): False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-20 00:07:20.949058: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-20 00:07:21.005671: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2256] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2024-03-20 00:07:21.014617: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-20 00:07:21.014811: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2256] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Check TensorFlow version\n",
    "print(\"TensorFlow Version:\", tf.__version__)\n",
    "\n",
    "# List available GPUs in TensorFlow\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            print(\"GPU:\", gpu)\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        print(\"GPUs available: \", len(gpus))\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "else:\n",
    "    print(\"No GPUs found.\")\n",
    "\n",
    "# Check if TensorFlow was built with CUDA\n",
    "print(\"Built with CUDA:\", tf.test.is_built_with_cuda())\n",
    "\n",
    "# Check if a GPU is available and if TensorFlow can access it\n",
    "print(\"GPU available (TensorFlow):\", tf.test.is_gpu_available())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
